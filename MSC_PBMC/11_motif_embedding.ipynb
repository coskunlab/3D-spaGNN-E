{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn.models import autoencoder\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "  \n",
    "  def __init__(self, in_channels, hidden_size, out_channels, dropout):\n",
    "    super(GCNEncoder, self).__init__()\n",
    "    self.conv1 = GCNConv(in_channels, hidden_size)\n",
    "    self.conv2 = GCNConv(hidden_size, out_channels)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  # Our model will take the feature matrix X and the edge list\n",
    "  # representation of the graph as inputs.\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.conv1(x, edge_index).relu()\n",
    "    x = self.dropout(x)\n",
    "    return self.conv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gae_train(train_data, gae_model, optimizer):\n",
    "    gae_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = gae_model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = gae_model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def gae_test(test_data, gae_model):\n",
    "    gae_model.eval()\n",
    "    z = gae_model.encode(test_data.x, test_data.edge_index)\n",
    "    return gae_model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, combine into a single-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = r'..\\..\\coculture_diagonal\\primed_pbmc\\00_analysis\\gae_encoder_explainer\\cd8\\detected_motifs'\n",
    "motif_l = os.listdir(in_dir)\n",
    "motif_l.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = ['set3']\n",
    "\n",
    "models_dir = r'..\\..\\coculture_diagonal\\primed_pbmc\\00_analysis\\embedded_features\\cd8'\n",
    "models = {}\n",
    "for s in sets:\n",
    "    models[s] = torch.load(os.path.join(models_dir, f'cd8_autoencoder_{s}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in models.keys():\n",
    "    models[k].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_pickle(os.path.join(in_dir, motif_l[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[16, 15], edge_index=[2, 62])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(temp['motif_features'].values[:,:-2].astype('float'))\n",
    "edge_index = torch.LongTensor(np.array(temp['motif_edges']).T)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "t2 = T.Compose([T.ToUndirected()])\n",
    "transformed_data = t2(data)\n",
    "transformed_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_embed = models['set3'].encode(transformed_data.x, transformed_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3188/3188 [00:05<00:00, 586.46it/s]  \n"
     ]
    }
   ],
   "source": [
    "data_sets = {'set3':{'x':[], 'edge_index':[]}}\n",
    "motif_id = []\n",
    "patch_id = []\n",
    "for motif in tqdm(motif_l):\n",
    "    s = motif.split('_')[0]\n",
    "    if s not in data_sets.keys():\n",
    "        continue\n",
    "    data = pd.read_pickle(os.path.join(in_dir, motif))\n",
    "    data_sets[s]['x'].append(data['motif_features'])\n",
    "    data_sets[s]['edge_index'].append(data['motif_edges'])\n",
    "    if len(data['motif_edges']) == 0:\n",
    "        print(motif)\n",
    "\n",
    "    motif_id = motif_id + [motif.split('.')[0]] * data['motif_features'].shape[0]\n",
    "    patch_id = patch_id + data['motif_patches']['patch_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets_combined = {}\n",
    "for k in data_sets.keys():\n",
    "    x_temp = []\n",
    "    edge_temp = []\n",
    "    curr_edge_shape = 0\n",
    "    for i in range(len(data_sets[k]['x'])):\n",
    "        x_temp.append(data_sets[k]['x'][i].values[:,:-2].astype('float'))\n",
    "        edge_temp.append(np.array(data_sets[k]['edge_index'][i]).T + curr_edge_shape)\n",
    "        if np.array(data_sets[k]['edge_index'][i]).T.shape[0] == 0:\n",
    "            print(i)\n",
    "        curr_edge_shape += data_sets[k]['x'][i].values[:,:-2].astype('float').shape[0]\n",
    "    data_sets_combined[k] = {'x':np.vstack(x_temp), 'edge_index':np.hstack(edge_temp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {}\n",
    "for k in data_sets.keys():\n",
    "    with torch.no_grad():\n",
    "        z_embed = models[k].encode(torch.Tensor(data_sets_combined[k]['x']).to(device),\n",
    "                                   torch.LongTensor(data_sets_combined[k]['edge_index']).to(device))\n",
    "        embedding[k] = z_embed.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = r'..\\..\\coculture_diagonal\\primed_pbmc\\00_analysis\\gae_encoder_explainer\\cd8\\motif_embedding'\n",
    "curr_shape = 0\n",
    "for k in data_sets.keys():\n",
    "    motif_embedding = pd.DataFrame(embedding[k], columns=[f'emb_{i}' for i in range(embedding[k].shape[1])])\n",
    "    motif_embedding['motif_id'] = motif_id[curr_shape:curr_shape + embedding[k].shape[0]]\n",
    "    motif_embedding['patch_id'] = patch_id[curr_shape:curr_shape + embedding[k].shape[0]]\n",
    "    curr_shape = curr_shape + embedding[k].shape[0]\n",
    "    motif_embedding.to_csv(os.path.join(out_dir, f'{k}_motif_embedding.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
